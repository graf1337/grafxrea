1) Задание 11: ResNet блоки с skip connections 
 
Задача: реализовать ResNet архитектуру с остаточными блоками. 
 
Требования: 
Residual блок: Conv → BatchNorm → ReLU → Conv → BatchNorm + skip → ReLU 
Bottleneck блок для уменьшения размерности 
Адаптация skip connection при изменении размерности 
ResNet-50 архитектура

2) Алгоритм работы НС по блокам

1. Стартовый блок (stem)
Conv7×7, 64 фильтра, шаг 2: извлекаются первые пространственные признаки (края, простые текстуры).​

BatchNorm выравнивает распределение активаций по батчу.

ReLU зануляет отрицательные значения, добавляя нелинейность.

MaxPool 3×3, шаг 2 уменьшает размер карты признаков, оставляя сильные отклики.​

Выход: примерно 
56
×
56
×
64
56×56×64.

2. Обычный residual‑блок
Для ResidualBlock с фильтрами 
F
F и stride 
s
s:​

Основной путь:

Conv3×3 (F, stride=s) → BatchNorm → ReLU.

Conv3×3 (F, stride=1) → BatchNorm.

Skip‑ветка:

Если размер и число каналов совпадают, skip = identity.

Если stride≠1 или меняется число каналов, по skip идёт 1×1 Conv(F, stride=s) + BatchNorm для выравнивания формы.

Сложение: out = main + skip.

ReLU на сумме.

Смысл: блок учит не полное отображение 
H(x)
H(x), а остаток 
F(x)=H(x)−x
F(x)=H(x)−x, а итог 
H(x)=F(x)+x
H(x)=F(x)+x.​

3. Bottleneck‑блок
В ResNet‑50 используются bottleneck‑блоки для глубины без взрыва параметров:​

1×1 Conv (filters/4, stride=s) → BN → ReLU: уменьшает число каналов (bottleneck).

3×3 Conv (filters/4, stride=1) → BN → ReLU: извлекает пространственные паттерны на сжатом представлении.

1×1 Conv (filters, stride=1) → BN: восстанавливает число каналов.

Skip‑ветка:

Если размер/каналы совпадают: identity.

Иначе 1×1 Conv(filters, stride=s) + BN.

Сумма основного пути и skip → ReLU.

Bottleneck уменьшает вычисления и параметры, позволяя строить более глубокую сеть (50 слоёв и больше).​

4. Стадии ResNet‑50
После stem идут 4 стадии:​

Stage 1 (conv2_x): 3 bottleneck‑блока с 64 выходными каналами, stride=1 в первом.

Stage 2 (conv3_x): 4 блока с 128 каналами, в первом блоке stride=2 (downsampling по пространству).

Stage 3 (conv4_x): 6 блоков с 256 каналами, первый со stride=2.

Stage 4 (conv5_x): 3 блока с 512 каналами, первый со stride=2.

На каждом переходе между стадиями первая ячейка уменьшает высоту/ширину и увеличивает число каналов, а skip‑ветка адаптируется 1×1‑свёрткой.​

5. Выходной блок и визуализация
GlobalAveragePooling2D усредняет каждую карту признаков по всем пространственным координатам, превращая тензор 
H×W×C в вектор длины CC.​

Dense(num_classes, softmax) даёт распределение вероятностей по классам.

Для визуализации работы сети берутся выходы нескольких промежуточных слоёв (например, conv1, pool1, один из bottleneck‑блоков, avg_pool), строится отдельная модель, возвращающая эти активации, и они отображаются как карты признаков/графики для тестового изображения.

3) Ответ на контрольный вопрос 
Type-I нечёткие множества имеют функцию принадлежности μ_A(x), которая принимает одно скалярное значение из для каждого элемента x, то есть степень принадлежности точно определена числом, например μ(высокий, 170см) = 0.8. Type-II (ultrafuzzy) нечёткие множества вводят дополнительный уровень неопределённости: функция принадлежности сама становится нечёткой и задаётся вторичной функцией μ_A(x,u), где u ∈ — это возможные значения первичной принадлежности, а μ_A(x,u) показывает степень уверенности в том, что μ_A(x) = u. Это создаёт "облако" неопределённости вокруг каждого значения принадлежности, что позволяет моделировать не только нечёткость самих данных, но и неопределённость в выборе самой функции принадлежности, например вместо точного 0.8 получается интервал [0.7, 0.9] с распределением уверенности по этим значениям. В результате Type-II множества сложнее вычислительно, но лучше справляются с задачами, где эксперт не уверен в параметрах нечётких правил.
